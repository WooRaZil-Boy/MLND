{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "\n",
    "http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1. Ordinary Least Squares\n",
    "손실을 최소로하는 직선 구하기. 각 값의 에러 제곱의 합이 최소가 되는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "reg.fit ([[0, 0], [1, 1], [2, 2]], [0, 1, 2]) #x = [[0, 0], [1, 1], [2, 2]], y = [0, 1, 2]\n",
    "#fit( X , y , sample_weight = None )\n",
    "#LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "reg.coef_ #coef_는 각 feature에 해당하는 weight. #coefficient\n",
    "#reg.intercept_로 bias를 구할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Variance score: 0.47\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nByF/dHPJTTwJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11824bf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes() #당뇨병 데이터 셋 불러오기\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2] #각 데이터에서 2번째 인덱스의 값만 추출\n",
    "# np.newaxis : 새로운 축을 추가한다.\n",
    "\n",
    "# 축 추가 전 \n",
    "# array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
    "#         -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613]])\n",
    "# diabetes.data[:1, 2] : array([ 0.06169621])\n",
    "\n",
    "# 축 추가 후\n",
    "# array([[[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
    "#          -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613]]])\n",
    "# diabetes.data[:1, np.newaxis, 2] : array([[ 0.06169621]])\n",
    "# []갯수 확인\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20] #20개를 뺀 나머지로 트레인\n",
    "diabetes_X_test = diabetes_X[-20:] #20개로 테스트\n",
    "#위에서 축을 추가했기에 2차원 배열. 추가하지 않고 그냥 split하면 각 배열이 1차원으로 된다. \n",
    "#fit()함수에 맞추기 위해 축을 추가한다.\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20] #20개를 뺀 나머지로 트레인\n",
    "diabetes_y_test = diabetes.target[-20:] #20개로 테스트\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression() #모델 생성\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train) #train_x, train_y로 모델 학습.\n",
    "#fit 함수에 맞추기 위해 위에서 축 추가\n",
    "#fit( X , y , sample_weight = None )\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_) #가중치 값 출력. input이 하나이기에 여기선 coef_ 반환값도 하나\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n",
    "#오차 제곱의 평균.\n",
    "#regr.predict(diabetes_X_test)의 값으로 예측 값 배열을 받아와 각 정답레이블과의 오차를 구하고 제곱해 평균.\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test)) \n",
    "#score(X, y[, sample_weight]) : R2 점수를 반환한다. 1이 max\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test, color='black') \n",
    "#x축: diabetes_X_test, y축: diabetes_y_test으로 scatter 차트\n",
    "plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "#x축: diabetes_X_test, y축: regr.predict(diabetes_X_test)으로 line 그리기\n",
    "\n",
    "plt.xticks(()) #x축 지표 표시 : 빈 칸으로 두면 없앤다. \n",
    "plt.yticks(()) #y축 지표 표시 : 빈 칸으로 두면 없앤다.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
